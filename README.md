This project is a gesture-controlled cursor movement system developed using Python, OpenCV, MediaPipe, and PyAutoGUI. It enables users to interact with their computer using only hand gestures captured through a webcam, eliminating the need for traditional input devices like a mouse or trackpad.

The system is capable of real-time hand tracking and gesture recognition to perform essential mouse actions such as cursor movement, left click, right click, and even screen brightness control. It is especially useful for individuals with physical disabilities, hygiene-sensitive environments, or users seeking innovative interaction methods.

Designed for ease of use, the application provides an intuitive user experience with minimal setup and high responsiveness. It is highly customizable, allowing future enhancements like gesture training, UI overlays, or multi-gesture commands.

The project serves as a step toward more inclusive, touchless human-computer interaction and can be extended for applications in gaming, virtual reality, smart home systems, and assistive technologies.
